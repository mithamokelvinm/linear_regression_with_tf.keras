{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTE98invUKuco0Wp8ig4Gc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithamokelvinm/linear_regression_with_tf.keras/blob/main/Validation_Sets_and_Test_Sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation Sets and Test Sets**\n",
        "\n",
        "In the previous exercises, we evaluated the trained model aganist the training set. which does not provide a strong signal about the quality of the model.\n",
        "\n",
        "Here, we'll experiment with validation sets and test sets."
      ],
      "metadata": {
        "id": "FPxlrH8Ta-1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives**\n",
        "\n",
        "We'll learn to:\n",
        "- Split a training set into a smaller training set and a validation set.\n",
        "- Analyze deltas between the training set and validation set results.\n",
        "- Test the trained model with a test set to determine whether your trained model is overfitting.\n",
        "- Detect and fix a common training problem."
      ],
      "metadata": {
        "id": "Aa7Lw-klckNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Dataset**\n",
        "\n",
        "This exercise uses the California Housing Dataset to predict the `median_house_value` at the cityblock level.\n",
        "\n",
        "Like many famous datasets, the California Housing Dataset actually consists of two separate datasets each living in separate .csv files:\n",
        "- The training set is in california_housing_train.csv\n",
        "- The test set is in california_housing_test.csv\n",
        "\n",
        "You'll create the validation set by dividing the downloaded training set into two parts:\n",
        "- A smaller training set\n",
        "- A validation set"
      ],
      "metadata": {
        "id": "khMdv1TTdjrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Relevant Modules**"
      ],
      "metadata": {
        "id": "1MkTVO1Mf6Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "metadata": {
        "id": "-LfE5q5agA9I"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the datasets from the internet**\n",
        "\n",
        "The following two code cells loads the separate .csv files and creates the following two pandas dataframes:\n",
        "- `train_df` which contains the training set.\n",
        "- `test_df` which contains the test set."
      ],
      "metadata": {
        "id": "UIsJllzngpTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
      ],
      "metadata": {
        "id": "FHVU1BsahTIy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scale the label values**"
      ],
      "metadata": {
        "id": "0n8lv0cEiLjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the label values\n",
        "scale_factor = 1000.0\n",
        "\n",
        "# Scale the training set's label\n",
        "train_df[\"median_house_value\"] /= scale_factor\n",
        "\n",
        "# Scale the test set's label\n",
        "test_df[\"median_house_value\"] /= scale_factor"
      ],
      "metadata": {
        "id": "UN3dpe5xiSWR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the functions that build and train a model**\n",
        "\n",
        "The following code cell defines two functions:\n",
        "- `build_model` which defines the model's topography\n",
        "- `train_model` which will ultimately train the model, outputtin not only the loss value for the training set but also loss value for the validation set."
      ],
      "metadata": {
        "id": "lx0anVisjAyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units = 1, input_shape = (1,)))\n",
        "\n",
        "  # Compile the model topography into code that TensorFlow can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = my_learning_rate),\n",
        "                loss = \"mean_squared_error\",\n",
        "                metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, df, feature, label, my_epochs,\n",
        "                my_batch_size = None, my_validation_split = 0.1):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  history = model.fit(x = df[feature],\n",
        "                      y = df[label],\n",
        "                      batch_size = my_batch_size,\n",
        "                      epochs = my_epochs,\n",
        "                      validation_split = my_validation_split)\n",
        "  \n",
        "  # Gather the model' trained weight and bias\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Isolate the root mean squared error for each epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history\n",
        "\n",
        "\n",
        "print(\"Defined the build_model amd train_model functions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNzBkcWgjs7i",
        "outputId": "9316f987-b52e-4657-fb7f-c80f38ca6af4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the build_model amd train_model functions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the plotting functions**\n",
        "\n",
        "The `plot_the_loss_curve` plots loss vs. epochs for both the training set and the validation set."
      ],
      "metadata": {
        "id": "30kOsJqVn72C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the plotting functions\n",
        "def plot_the_loss_curve(epochs, mae_training, mae_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mae_training[1:], label = \"Training Loss\")\n",
        "  plt.plot(epochs[1:], mae_validation[1:], label = \"Validation Loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  # We're not going to plot the first epoch, since the loss on the\n",
        "  # first epoch is often substantially greater than the loss for \n",
        "  # the other epochs.\n",
        "  merged_mae_list = mae_training[1:] + mae_validation[1:]\n",
        "  highest_loss = max(merged_mae_list)\n",
        "  lowest_loss = min(merged_mae_list)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "\n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg5X1cgbpEHs",
        "outputId": "a4ff0d89-8813-4675-99b8-50407f5a4c75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_the_loss_curve function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1: Experiment with validation splits**\n",
        "\n",
        "In the following code cell, we'll see a variable named `validation_split`, which is initialized as 0.2.\n",
        "\n",
        "The `validation_split` variable specifies the proportion of the original training set that will serve as the validation set.\n",
        "\n",
        "The original training set contains 17,000 examples.\n",
        "\n",
        "Therefore, a `validation_split` of 0.2 means that:\n",
        "- 17000 * 0.2 ~= 3,400 examples will therefore become the validation set.\n",
        "- 17000 * 0.8 ~= 13,600 examples will therefore become the training set.\n",
        "\n",
        "The following code builds a model, trains it on the training set, and evaluates the built model on both:\n",
        "- The `training_set`\n",
        "- And the `validation_set`\n",
        "\n",
        "If the data in the training set is similar to the data in the validation set, then the two loss curves and the final loss values should be almost identical.\n",
        "\n",
        "However, the loss curves and final loss values are not almost identical. Hmm, that's odd.\n",
        "\n",
        "Experiement with two or three different values of the `validation_split`\n",
        "\n",
        "Do different values of `validation_split` fix the problem?"
      ],
      "metadata": {
        "id": "Dne79MU4sH2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following variables are the hyperparameters\n",
        "learning_rate = 0.08\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into reduced training set and a validation set\n",
        "validation_split = 0.2\n",
        "\n",
        "# Identify the feature and the label\n",
        "my_feature = \"median_income\"  # the median income on a specific city block\n",
        "my_label = \"median_house_value\"  # the median house value in a specific city block\n",
        "# That is, we're going to create a model that predicts house value based soley\n",
        "# on the neighbourhood's median income.\n",
        "\n",
        "# Invoke the functions to build and train the model\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, train_df, my_feature,\n",
        "                                    my_label, epochs, batch_size, \n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zAlGNU_CyrNF",
        "outputId": "ae22be83-59f5-46f6-ee88-9bab80e3902b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 1s 3ms/step - loss: 41842.8828 - root_mean_squared_error: 204.5553 - val_loss: 50740.0898 - val_root_mean_squared_error: 225.2556\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 24304.5215 - root_mean_squared_error: 155.8991 - val_loss: 29909.0781 - val_root_mean_squared_error: 172.9424\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 12916.9297 - root_mean_squared_error: 113.6527 - val_loss: 16251.6729 - val_root_mean_squared_error: 127.4820\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 7502.8960 - root_mean_squared_error: 86.6193 - val_loss: 9831.4990 - val_root_mean_squared_error: 99.1539\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6518.3584 - root_mean_squared_error: 80.7364 - val_loss: 9298.7217 - val_root_mean_squared_error: 96.4299\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.2402 - root_mean_squared_error: 80.7047 - val_loss: 9208.1768 - val_root_mean_squared_error: 95.9592\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6512.4434 - root_mean_squared_error: 80.6997 - val_loss: 9343.9551 - val_root_mean_squared_error: 96.6641\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.8179 - root_mean_squared_error: 80.7082 - val_loss: 9257.7402 - val_root_mean_squared_error: 96.2171\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6511.7700 - root_mean_squared_error: 80.6955 - val_loss: 9450.5361 - val_root_mean_squared_error: 97.2139\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6512.5718 - root_mean_squared_error: 80.7005 - val_loss: 9201.4971 - val_root_mean_squared_error: 95.9244\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.9731 - root_mean_squared_error: 80.7092 - val_loss: 9137.2598 - val_root_mean_squared_error: 95.5890\n",
            "Epoch 12/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6514.2700 - root_mean_squared_error: 80.7110 - val_loss: 9287.3018 - val_root_mean_squared_error: 96.3707\n",
            "Epoch 13/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.4253 - root_mean_squared_error: 80.7058 - val_loss: 9259.2246 - val_root_mean_squared_error: 96.2249\n",
            "Epoch 14/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.0342 - root_mean_squared_error: 80.7034 - val_loss: 9228.7275 - val_root_mean_squared_error: 96.0663\n",
            "Epoch 15/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6514.0249 - root_mean_squared_error: 80.7095 - val_loss: 9280.4814 - val_root_mean_squared_error: 96.3353\n",
            "Epoch 16/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.7266 - root_mean_squared_error: 80.7077 - val_loss: 9268.2109 - val_root_mean_squared_error: 96.2715\n",
            "Epoch 17/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.8770 - root_mean_squared_error: 80.7086 - val_loss: 9322.2549 - val_root_mean_squared_error: 96.5518\n",
            "Epoch 18/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.5464 - root_mean_squared_error: 80.7065 - val_loss: 9263.6543 - val_root_mean_squared_error: 96.2479\n",
            "Epoch 19/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.7310 - root_mean_squared_error: 80.7077 - val_loss: 9280.7959 - val_root_mean_squared_error: 96.3369\n",
            "Epoch 20/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.7505 - root_mean_squared_error: 80.7078 - val_loss: 9205.4531 - val_root_mean_squared_error: 95.9451\n",
            "Epoch 21/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6514.0542 - root_mean_squared_error: 80.7097 - val_loss: 9302.6074 - val_root_mean_squared_error: 96.4500\n",
            "Epoch 22/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6512.7949 - root_mean_squared_error: 80.7019 - val_loss: 9180.9521 - val_root_mean_squared_error: 95.8173\n",
            "Epoch 23/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.2412 - root_mean_squared_error: 80.7047 - val_loss: 9290.2783 - val_root_mean_squared_error: 96.3861\n",
            "Epoch 24/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.5459 - root_mean_squared_error: 80.7065 - val_loss: 9251.6621 - val_root_mean_squared_error: 96.1856\n",
            "Epoch 25/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.3379 - root_mean_squared_error: 80.7053 - val_loss: 9210.9492 - val_root_mean_squared_error: 95.9737\n",
            "Epoch 26/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6512.7222 - root_mean_squared_error: 80.7014 - val_loss: 9428.7119 - val_root_mean_squared_error: 97.1016\n",
            "Epoch 27/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.9033 - root_mean_squared_error: 80.7088 - val_loss: 9350.2285 - val_root_mean_squared_error: 96.6966\n",
            "Epoch 28/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6512.4346 - root_mean_squared_error: 80.6997 - val_loss: 9263.8125 - val_root_mean_squared_error: 96.2487\n",
            "Epoch 29/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6513.6411 - root_mean_squared_error: 80.7071 - val_loss: 9334.0996 - val_root_mean_squared_error: 96.6131\n",
            "Epoch 30/30\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6509.6699 - root_mean_squared_error: 80.6825 - val_loss: 9348.3408 - val_root_mean_squared_error: 96.6868\n",
            "92.2598876953125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Determine why the loss curves differ**\n",
        "\n",
        "No matter how you split the trainning set and validation set, the loss curves differ significantly.\n",
        "\n",
        "Evidently, the data in th training set isn't similar enough to the data in the validation set. Counterintuitive? Yes, but this problem is pretty common in machine learning.\n",
        "\n",
        "Our task is to determine why the loss curves aren't highly similar.\n",
        "\n",
        "As with most issues in machine learning, the problem is rooted in the data itself. \n",
        "\n",
        "To solve this mystery, of why the training set and the validation set aren't almost identical, write a line or two of Pandas code in the following code cell.\n",
        "\n",
        "Here are a couple of hints:\n",
        "- A reduced training set (the original training set - the validation set)\n",
        "- The validation set\n",
        "\n",
        "By default, the pandas `head()` method outputs the first five rows of the DataFrame. To see more of the training set, specify the n argument to head and assign a large posive integer to n."
      ],
      "metadata": {
        "id": "4UxPi9dn1NQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write some code in this cell\n",
        "\n",
        "# Examine examples 0 through 4 and examples 995 through 999 of the training set\n",
        "train_df.head(n=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "McJS8ZrV5oi_",
        "outputId": "7a6f60a5-88da-471e-c33a-b74a8c343911"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -114.3      34.2                15.0       5612.0          1283.0   \n",
              "1       -114.5      34.4                19.0       7650.0          1901.0   \n",
              "2       -114.6      33.7                17.0        720.0           174.0   \n",
              "3       -114.6      33.6                14.0       1501.0           337.0   \n",
              "4       -114.6      33.6                20.0       1454.0           326.0   \n",
              "..         ...       ...                 ...          ...             ...   \n",
              "995     -117.1      32.5                 8.0       6533.0          1217.0   \n",
              "996     -117.1      34.6                 6.0       5110.0          1044.0   \n",
              "997     -117.1      34.2                22.0       4397.0           931.0   \n",
              "998     -117.1      34.0                24.0       4144.0           826.0   \n",
              "999     -117.1      33.6                 6.0       1868.0           289.0   \n",
              "\n",
              "     population  households  median_income  median_house_value  \n",
              "0        1015.0       472.0            1.5                66.9  \n",
              "1        1129.0       463.0            1.8                80.1  \n",
              "2         333.0       117.0            1.7                85.7  \n",
              "3         515.0       226.0            3.2                73.4  \n",
              "4         624.0       262.0            1.9                65.5  \n",
              "..          ...         ...            ...                 ...  \n",
              "995      4797.0      1177.0            4.0               144.4  \n",
              "996      1938.0       724.0            3.2               112.8  \n",
              "997      1145.0       445.0            4.5               108.4  \n",
              "998      2127.0       772.0            2.5                96.0  \n",
              "999       750.0       247.0            4.4               307.6  \n",
              "\n",
              "[1000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08926fe0-9c2b-4830-9a01-a37543b31b3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>32.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6533.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>4797.0</td>\n",
              "      <td>1177.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>144.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5110.0</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>1938.0</td>\n",
              "      <td>724.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>112.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.2</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4397.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1145.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>108.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4144.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>772.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-117.1</td>\n",
              "      <td>33.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1868.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>307.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08926fe0-9c2b-4830-9a01-a37543b31b3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08926fe0-9c2b-4830-9a01-a37543b31b3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08926fe0-9c2b-4830-9a01-a37543b31b3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find that the original training set is sorted by longitude.\n",
        "\n",
        "Apparently, longitude influences the relationship of `total_rooms` to `median_house_value`."
      ],
      "metadata": {
        "id": "eIaf1gM55--x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: Fix the problem**\n",
        "\n",
        "To fix the problem, shuffle the examples in the training set before splitting the examples into a training set and a validation set.\n",
        "\n",
        "To do so, take the following steps:\n",
        "- Shuffle the data in the training set by adding the following line anywhere before you call `train_model` (In the code cell associated with Task 1):\n",
        "\n",
        "`shuffled_train_df = train_df.reindex(np.random.permutations(train_df.index)`\n",
        "- Pass `shuffled_train_df` (instead of `train_df`) as the second argument to `train_model` (In the code cell associated with task 1) so that the call becomes as folows:\n",
        "\n",
        "`epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature, my_label, epochs, batch_size, \n",
        "validation_split)`"
      ],
      "metadata": {
        "id": "FuYc65K47Hsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The complete implementation**"
      ],
      "metadata": {
        "id": "d5IGKVZk9try"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The following variables are the hyperparameters\n",
        "learning_rate = 0.08\n",
        "epochs = 70\n",
        "batch_size = 100\n",
        "\n",
        "# Split the original training set into a reduced training set and a validation set\n",
        "validation_split = 0.2\n",
        "\n",
        "# Identify the feature and the label\n",
        "my_feature = \"median_income\"  # the median income on a specific city block\n",
        "my_label = \"median_house_value\"  # the median house value on a specific city block\n",
        "# That is, we're going to create a model that predicts house value based soley\n",
        "# on the neighbourhood's median income.\n",
        "\n",
        "# Shuffle the examples\n",
        "shuffled_train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
        "\n",
        "# Invoke the functions to build and train the model\n",
        "# Train on the shuffled training set\n",
        "my_model = build_model(learning_rate)\n",
        "epochs, rmse, history = train_model(my_model, shuffled_train_df, my_feature,\n",
        "                                    my_label, epochs, batch_size,\n",
        "                                    validation_split)\n",
        "\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"],\n",
        "                    history[\"val_root_mean_squared_error\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RtgJi9_K-ZkJ",
        "outputId": "f6d98ed9-89a9-494f-d87b-d584e8ed6b7e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "136/136 [==============================] - 1s 2ms/step - loss: 45060.0039 - root_mean_squared_error: 212.2734 - val_loss: 34552.7383 - val_root_mean_squared_error: 185.8837\n",
            "Epoch 2/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 26499.3574 - root_mean_squared_error: 162.7862 - val_loss: 19414.1152 - val_root_mean_squared_error: 139.3345\n",
            "Epoch 3/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 14326.5645 - root_mean_squared_error: 119.6936 - val_loss: 10372.9951 - val_root_mean_squared_error: 101.8479\n",
            "Epoch 4/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 8195.7139 - root_mean_squared_error: 90.5302 - val_loss: 7203.0771 - val_root_mean_squared_error: 84.8709\n",
            "Epoch 5/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6993.5708 - root_mean_squared_error: 83.6276 - val_loss: 7114.6743 - val_root_mean_squared_error: 84.3485\n",
            "Epoch 6/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.1411 - root_mean_squared_error: 83.6071 - val_loss: 7114.1343 - val_root_mean_squared_error: 84.3453\n",
            "Epoch 7/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.8735 - root_mean_squared_error: 83.5995 - val_loss: 7117.7798 - val_root_mean_squared_error: 84.3669\n",
            "Epoch 8/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6987.0771 - root_mean_squared_error: 83.5887 - val_loss: 7122.2676 - val_root_mean_squared_error: 84.3935\n",
            "Epoch 9/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.7329 - root_mean_squared_error: 83.5986 - val_loss: 7114.2100 - val_root_mean_squared_error: 84.3458\n",
            "Epoch 10/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.0337 - root_mean_squared_error: 83.6004 - val_loss: 7114.0981 - val_root_mean_squared_error: 84.3451\n",
            "Epoch 11/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.5200 - root_mean_squared_error: 83.5974 - val_loss: 7114.3999 - val_root_mean_squared_error: 84.3469\n",
            "Epoch 12/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.3569 - root_mean_squared_error: 83.5964 - val_loss: 7121.6284 - val_root_mean_squared_error: 84.3897\n",
            "Epoch 13/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.7817 - root_mean_squared_error: 83.6109 - val_loss: 7114.1094 - val_root_mean_squared_error: 84.3452\n",
            "Epoch 14/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.1987 - root_mean_squared_error: 83.5954 - val_loss: 7116.2363 - val_root_mean_squared_error: 84.3578\n",
            "Epoch 15/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.7539 - root_mean_squared_error: 83.6048 - val_loss: 7114.8916 - val_root_mean_squared_error: 84.3498\n",
            "Epoch 16/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.9043 - root_mean_squared_error: 83.5997 - val_loss: 7114.3813 - val_root_mean_squared_error: 84.3468\n",
            "Epoch 17/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6987.8511 - root_mean_squared_error: 83.5934 - val_loss: 7114.1177 - val_root_mean_squared_error: 84.3452\n",
            "Epoch 18/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.6216 - root_mean_squared_error: 83.6040 - val_loss: 7114.7090 - val_root_mean_squared_error: 84.3487\n",
            "Epoch 19/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.4375 - root_mean_squared_error: 83.6029 - val_loss: 7118.8359 - val_root_mean_squared_error: 84.3732\n",
            "Epoch 20/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.5459 - root_mean_squared_error: 83.6095 - val_loss: 7114.8657 - val_root_mean_squared_error: 84.3497\n",
            "Epoch 21/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.4741 - root_mean_squared_error: 83.6091 - val_loss: 7114.3179 - val_root_mean_squared_error: 84.3464\n",
            "Epoch 22/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.0430 - root_mean_squared_error: 83.6005 - val_loss: 7121.9194 - val_root_mean_squared_error: 84.3915\n",
            "Epoch 23/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.9458 - root_mean_squared_error: 83.5999 - val_loss: 7114.4980 - val_root_mean_squared_error: 84.3475\n",
            "Epoch 24/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.3857 - root_mean_squared_error: 83.6085 - val_loss: 7115.0059 - val_root_mean_squared_error: 84.3505\n",
            "Epoch 25/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.5781 - root_mean_squared_error: 83.6037 - val_loss: 7115.1606 - val_root_mean_squared_error: 84.3514\n",
            "Epoch 26/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.2480 - root_mean_squared_error: 83.5957 - val_loss: 7118.6885 - val_root_mean_squared_error: 84.3723\n",
            "Epoch 27/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.2588 - root_mean_squared_error: 83.6078 - val_loss: 7114.1313 - val_root_mean_squared_error: 84.3453\n",
            "Epoch 28/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.7949 - root_mean_squared_error: 83.5990 - val_loss: 7114.1851 - val_root_mean_squared_error: 84.3456\n",
            "Epoch 29/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.7241 - root_mean_squared_error: 83.6046 - val_loss: 7115.1396 - val_root_mean_squared_error: 84.3513\n",
            "Epoch 30/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.8726 - root_mean_squared_error: 83.6055 - val_loss: 7114.6528 - val_root_mean_squared_error: 84.3484\n",
            "Epoch 31/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.7563 - root_mean_squared_error: 83.6048 - val_loss: 7114.1758 - val_root_mean_squared_error: 84.3456\n",
            "Epoch 32/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.3994 - root_mean_squared_error: 83.6026 - val_loss: 7114.9746 - val_root_mean_squared_error: 84.3503\n",
            "Epoch 33/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.2666 - root_mean_squared_error: 83.6018 - val_loss: 7114.0713 - val_root_mean_squared_error: 84.3450\n",
            "Epoch 34/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.9966 - root_mean_squared_error: 83.6002 - val_loss: 7117.1172 - val_root_mean_squared_error: 84.3630\n",
            "Epoch 35/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.6016 - root_mean_squared_error: 83.6098 - val_loss: 7114.2070 - val_root_mean_squared_error: 84.3458\n",
            "Epoch 36/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.6187 - root_mean_squared_error: 83.5980 - val_loss: 7115.7266 - val_root_mean_squared_error: 84.3548\n",
            "Epoch 37/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.9399 - root_mean_squared_error: 83.5999 - val_loss: 7116.0801 - val_root_mean_squared_error: 84.3569\n",
            "Epoch 38/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.3584 - root_mean_squared_error: 83.6024 - val_loss: 7114.0938 - val_root_mean_squared_error: 84.3451\n",
            "Epoch 39/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.9170 - root_mean_squared_error: 83.5997 - val_loss: 7114.1528 - val_root_mean_squared_error: 84.3454\n",
            "Epoch 40/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.2583 - root_mean_squared_error: 83.6078 - val_loss: 7114.6924 - val_root_mean_squared_error: 84.3486\n",
            "Epoch 41/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.8188 - root_mean_squared_error: 83.6051 - val_loss: 7114.7837 - val_root_mean_squared_error: 84.3492\n",
            "Epoch 42/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.2695 - root_mean_squared_error: 83.6078 - val_loss: 7114.6782 - val_root_mean_squared_error: 84.3485\n",
            "Epoch 43/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.3169 - root_mean_squared_error: 83.6081 - val_loss: 7114.4092 - val_root_mean_squared_error: 84.3470\n",
            "Epoch 44/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.9043 - root_mean_squared_error: 83.6056 - val_loss: 7114.0996 - val_root_mean_squared_error: 84.3451\n",
            "Epoch 45/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6987.0552 - root_mean_squared_error: 83.5886 - val_loss: 7118.2822 - val_root_mean_squared_error: 84.3699\n",
            "Epoch 46/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.1152 - root_mean_squared_error: 83.6009 - val_loss: 7114.5801 - val_root_mean_squared_error: 84.3480\n",
            "Epoch 47/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.7808 - root_mean_squared_error: 83.6049 - val_loss: 7114.8301 - val_root_mean_squared_error: 84.3495\n",
            "Epoch 48/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.2393 - root_mean_squared_error: 83.6017 - val_loss: 7115.7661 - val_root_mean_squared_error: 84.3550\n",
            "Epoch 49/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.2676 - root_mean_squared_error: 83.6078 - val_loss: 7114.2329 - val_root_mean_squared_error: 84.3459\n",
            "Epoch 50/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.3423 - root_mean_squared_error: 83.6023 - val_loss: 7120.6523 - val_root_mean_squared_error: 84.3840\n",
            "Epoch 51/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.1982 - root_mean_squared_error: 83.6074 - val_loss: 7114.3218 - val_root_mean_squared_error: 84.3464\n",
            "Epoch 52/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.9912 - root_mean_squared_error: 83.6062 - val_loss: 7115.1123 - val_root_mean_squared_error: 84.3511\n",
            "Epoch 53/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.6470 - root_mean_squared_error: 83.6041 - val_loss: 7114.8408 - val_root_mean_squared_error: 84.3495\n",
            "Epoch 54/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.0239 - root_mean_squared_error: 83.6004 - val_loss: 7114.1455 - val_root_mean_squared_error: 84.3454\n",
            "Epoch 55/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.2739 - root_mean_squared_error: 83.6079 - val_loss: 7114.1284 - val_root_mean_squared_error: 84.3453\n",
            "Epoch 56/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.3242 - root_mean_squared_error: 83.6022 - val_loss: 7116.7632 - val_root_mean_squared_error: 84.3609\n",
            "Epoch 57/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.7236 - root_mean_squared_error: 83.5986 - val_loss: 7114.7402 - val_root_mean_squared_error: 84.3489\n",
            "Epoch 58/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.9399 - root_mean_squared_error: 83.6059 - val_loss: 7114.2930 - val_root_mean_squared_error: 84.3463\n",
            "Epoch 59/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.7051 - root_mean_squared_error: 83.6045 - val_loss: 7115.8604 - val_root_mean_squared_error: 84.3556\n",
            "Epoch 60/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.1616 - root_mean_squared_error: 83.6012 - val_loss: 7116.5098 - val_root_mean_squared_error: 84.3594\n",
            "Epoch 61/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.9707 - root_mean_squared_error: 83.6001 - val_loss: 7115.3184 - val_root_mean_squared_error: 84.3523\n",
            "Epoch 62/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.0630 - root_mean_squared_error: 83.6066 - val_loss: 7114.1167 - val_root_mean_squared_error: 84.3452\n",
            "Epoch 63/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6987.0439 - root_mean_squared_error: 83.5885 - val_loss: 7118.7305 - val_root_mean_squared_error: 84.3726\n",
            "Epoch 64/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.3804 - root_mean_squared_error: 83.6025 - val_loss: 7114.0830 - val_root_mean_squared_error: 84.3450\n",
            "Epoch 65/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6988.2676 - root_mean_squared_error: 83.5959 - val_loss: 7114.1460 - val_root_mean_squared_error: 84.3454\n",
            "Epoch 66/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.1621 - root_mean_squared_error: 83.6072 - val_loss: 7115.2798 - val_root_mean_squared_error: 84.3521\n",
            "Epoch 67/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.0522 - root_mean_squared_error: 83.6006 - val_loss: 7114.2500 - val_root_mean_squared_error: 84.3460\n",
            "Epoch 68/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.6987 - root_mean_squared_error: 83.6044 - val_loss: 7115.0938 - val_root_mean_squared_error: 84.3510\n",
            "Epoch 69/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6990.3115 - root_mean_squared_error: 83.6081 - val_loss: 7115.9839 - val_root_mean_squared_error: 84.3563\n",
            "Epoch 70/70\n",
            "136/136 [==============================] - 0s 2ms/step - loss: 6989.9492 - root_mean_squared_error: 83.6059 - val_loss: 7114.1616 - val_root_mean_squared_error: 84.3455\n",
            "79.19770050048828\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment with the `validation_split` to answer the following questions;\n",
        "- With the training set shuffled, is the final loss fot the training set closer to the final loss for the validation set?\n",
        "- At what range of values of `validation-split` do the final loss values for the training set and the validation set divulge meaningfully? Why?\n",
        "\n",
        "\n",
        "Yes, after shuffling the original training set, the final loss values for the training set and the validation set become more closer.\n",
        "\n",
        "If the validation split is < 0.15, the final loss values for the training set and the validation set divulge meaningfully.\n",
        "\n",
        "Apparently, the validation set no longer contains enough examples."
      ],
      "metadata": {
        "id": "zhkXsntBAvro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4: Use the Test Dataset to evaluate your model's perfomance**\n",
        "\n",
        "The test set usuually acts as the ultimate judge of a model's quality.\n",
        "\n",
        "The test set can serve as an impartial judge because it's examples haven't been used in training the model.\n",
        "\n",
        "Run the following code cell to evaluate the model with the test set:"
      ],
      "metadata": {
        "id": "cKiZVW9fClbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_df[my_feature]\n",
        "y_test = test_df[my_label]\n",
        "\n",
        "result = my_model.evaluate(x_test, y_test, batch_size = batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOqfVlkEDcDx",
        "outputId": "03151513-d3a0-4e96-a856-7cbd8a9ad48f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 0s 3ms/step - loss: 7010.6118 - root_mean_squared_error: 83.7294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the root mean squared error of the model when evaluated of the three datasets.\n",
        "\n",
        "Look for the root mean squared error in the final training epoch fo the `training_set` and `validation_set`, and examine the root mean squared error for the `test_set`.\n",
        "\n",
        "Ideally, the root mean squared error of all th tree sets should be similar. Are they?\n",
        "\n",
        "In our experiments, yes, the rmse values were similar enough."
      ],
      "metadata": {
        "id": "xV926XJhD3nU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ap3YenwE9Hr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}